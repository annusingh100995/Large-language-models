{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c36c744-d152-4e31-9890-51bc8ee48ada",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c72090-7007-4cac-aafc-5ce43dd2372d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d6cc8a3-6f9c-493f-b3d5-bf47834915bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0c4dcfe-ce73-434e-bf68-f1ed85f8addb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52fb95a1-ab86-41f2-82a8-2dcb4133345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Scrape Web Content\n",
    "def scrape_webpage(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    text = ' '.join([p.text for p in soup.find_all('p')])\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a584293-5d77-4191-a6d7-028d25171cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Chunk and Embed the Content\n",
    "def create_vector_db(text):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "    chunks = splitter.create_documents([text])\n",
    "    #embeddings = OpenAIEmbeddings()\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "    db = FAISS.from_documents(chunks, embeddings)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8bae5dc-dfa3-42cc-a74d-430156ac16d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Define tools for the Agent\n",
    "def setup_tools(db, llm):\n",
    "    retriever = db.as_retriever()\n",
    "\n",
    "    def search_tool_func(query):\n",
    "        docs = retriever.get_relevant_documents(query)\n",
    "        return '\\n'.join([doc.page_content for doc in docs])\n",
    "\n",
    "    search_tool = Tool(\n",
    "        name=\"WebSearch\",\n",
    "        func=search_tool_func,\n",
    "        description=\"Useful for searching the webpage for relevant content\"\n",
    "    )\n",
    "\n",
    "    summarize_prompt = PromptTemplate(\n",
    "        input_variables=[\"context\"],\n",
    "        template=\"Summarize the following content:\\n\\n{context}\"\n",
    "    )\n",
    "    summarize_chain = LLMChain(llm=llm, prompt=summarize_prompt)\n",
    "\n",
    "    def summarize_tool_func(text):\n",
    "        return summarize_chain.run(context=text)\n",
    "\n",
    "    summarize_tool = Tool(\n",
    "        name=\"Summarizer\",\n",
    "        func=summarize_tool_func,\n",
    "        description=\"Use this to summarize large context or search results\"\n",
    "    )\n",
    "\n",
    "    return [search_tool, summarize_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "509821f0-0f87-4678-8e5b-5f2a83bd1892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Run the Agent on a Query\n",
    "def run_agentic_rag(url, user_query):\n",
    "    print(f\"\\nüîó Scraping webpage: {url}\")\n",
    "    raw_text = scrape_webpage(url)\n",
    "\n",
    "    print(\"üß† Creating vector DB...\")\n",
    "    db = create_vector_db(raw_text)\n",
    "\n",
    "    print(\"ü§ñ Setting up agent...\")\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.3)\n",
    "    #llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "    tools = setup_tools(db, llm)\n",
    "    agent = initialize_agent(tools=tools, llm=llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "    print(\"üí¨ Running agent on query...\")\n",
    "    answer = agent.run(user_query)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a81726d-2c5a-4307-968f-00653e77bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.confident-ai.com/blog/llm-guardrails-the-ultimate-guide-to-safeguard-llm-systems\"  # Replace with a real, rich-text page\n",
    "query = \"What are prompt injections?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d51f06b5-5290-4c9f-8642-787aeefe7652",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó Scraping webpage: https://www.confident-ai.com/blog/llm-guardrails-the-ultimate-guide-to-safeguard-llm-systems\n",
      "üß† Creating vector DB...\n",
      "ü§ñ Setting up agent...\n",
      "üí¨ Running agent on query...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out what prompt injections are. I will use a web search to find a definition.\n",
      "Action: WebSearch\n",
      "Action Input: \"prompt injection definition\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mattempts to bypass instructions or coerce the system into executing unauthorized tasks. An example of an input that attempts a prompt injection is as follows: Fortunately, you can guard against it using DeepEval like this: The Jailbreaking Guard identifies and mitigates attempts to override system restrictions or ethical boundaries. Techniques it defends against include hypothetical scenarios, role-playing exploits, and logic-based attacks. Example of a jailbreaking input: You can guard it in\n",
      "way to safeguard against harmful user inputs. This not only conserves tokens by preventing the generation of inappropriate responses but also protects the overall integrity of your LLM application. If your LLM application is not user facing, you likely won√¢¬Ä¬ôt require input guards. The Prompt Injection Guard detects and prevents malicious inputs designed to manipulate prompts. It works by identifying attempts to bypass instructions or coerce the system into executing unauthorized tasks. An\n",
      "want to handle): To guard it with DeepEval: The Topical Guard restricts inputs to a predefined set of relevant topics. By verifying the relevance of user inputs, it helps maintain focus and consistency in the system√¢¬Ä¬ôs responses. The Toxicity Guard restricts inputs containing offensive, harmful, or abusive language to prevent the generation of outputs that could alienate or harm users. For example: You guessed it, we have it in DeepEval too: The Code Injection Guard restricts inputs designed\n",
      "exploits, and logic-based attacks. Example of a jailbreaking input: You can guard it in DeepEval like this: The Privacy Guard ensures user inputs do not contain sensitive or restricted information, such as Personally Identifiable Information (PII), confidential organizational data, medical records, or legal documents. Example of an input that leaks PII to the system (which you definitely don√¢¬Ä¬ôt want to handle): To guard it with DeepEval: The Topical Guard restricts inputs to a predefined set\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search result defines prompt injection as malicious inputs designed to manipulate prompts, attempting to bypass instructions or coerce the system into executing unauthorized tasks.\n",
      "Final Answer: Prompt injections are malicious inputs designed to manipulate prompts, attempting to bypass instructions or coerce the system into executing unauthorized tasks.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = run_agentic_rag(url, query)\n",
    "#print(\"\\nüîç Answer:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f92279ee-c3c6-4645-987a-d8d8c827bc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prompt injections are malicious inputs designed to manipulate prompts, attempting to bypass instructions or coerce the system into executing unauthorized tasks.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d688115-50bf-430f-8a1a-c083d062f0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Answer:\n",
      " Prompt injections are malicious inputs designed to manipulate prompts, attempting to bypass instructions or coerce the system into executing unauthorized tasks.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Answer:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b0006-5465-4cd5-89d2-3923662af224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
