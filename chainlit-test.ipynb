{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02786619-c020-403b-90e8-dc0fd0758463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-17 16:57:37 - Created default config file at D:\\Learnings\\LLM\\udemy_course\\llm_engineering\\practice\\.chainlit\\config.toml\n",
      "2025-04-17 16:57:37 - Created default translation directory at D:\\Learnings\\LLM\\udemy_course\\llm_engineering\\practice\\.chainlit\\translations\n",
      "2025-04-17 16:57:37 - Created default translation file at D:\\Learnings\\LLM\\udemy_course\\llm_engineering\\practice\\.chainlit\\translations\\bn.json\n",
      "2025-04-17 16:57:37 - Created default translation file at D:\\Learnings\\LLM\\udemy_course\\llm_engineering\\practice\\.chainlit\\translations\\en-US.json\n",
      "2025-04-17 16:57:37 - Created default translation file at D:\\Learnings\\LLM\\udemy_course\\llm_engineering\\practice\\.chainlit\\translations\\gu.json\n",
      "2025-04-17 16:57:37 - Created default translation file at D:\\Learnings\\LLM\\udemy_course\\llm_engineering\\practice\\.chainlit\\translations\\he-IL.json\n",
      "2025-04-17 16:57:37 - Created default translation file at D:\\Learnings\\LLM\\udemy_course\\llm_engineering\\practice\\.chainlit\\translations\\hi.json\n",
      "2025-04-17 16:57:37 - Created default translation file at D:\\Learnings\\LLM\\udemy_course\\llm_engineering\\practice\\.chainlit\\translations\\ja.json\n",
      "2025-04-17 16:57:37 - Created default translation file at D:\\Learnings\\LLM\\udemy_course\\llm_engineering\\practice\\.chainlit\\translations\\kn.json\n",
      "2025-04-17 16:57:37 - Created default translation file at D:\\Learnings\\LLM\\udemy_course\\llm_engineering\\practice\\.chainlit\\translations\\ml.json\n",
      "2025-04-17 16:57:37 - Created default translation file at D:\\Learnings\\LLM\\udemy_course\\llm_engineering\\practice\\.chainlit\\translations\\mr.json\n",
      "2025-04-17 16:57:37 - Created default translation file at D:\\Learnings\\LLM\\udemy_course\\llm_engineering\\practice\\.chainlit\\translations\\nl.json\n",
      "2025-04-17 16:57:37 - Created default translation file at D:\\Learnings\\LLM\\udemy_course\\llm_engineering\\practice\\.chainlit\\translations\\ta.json\n",
      "2025-04-17 16:57:37 - Created default translation file at D:\\Learnings\\LLM\\udemy_course\\llm_engineering\\practice\\.chainlit\\translations\\te.json\n",
      "2025-04-17 16:57:37 - Created default translation file at D:\\Learnings\\LLM\\udemy_course\\llm_engineering\\practice\\.chainlit\\translations\\zh-CN.json\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import Runnable\n",
    "from langchain.schema.runnable.config import RunnableConfig\n",
    "from typing import cast\n",
    "\n",
    "import chainlit as cl\n",
    "\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    model = ChatGoogleGenerativeAI(streaming=True)\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You're a very knowledgeable historian who provides accurate and eloquent answers to historical questions.\",\n",
    "            ),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "    runnable = prompt | model | StrOutputParser()\n",
    "    cl.user_session.set(\"runnable\", runnable)\n",
    "\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(message: cl.Message):\n",
    "    runnable = cast(Runnable, cl.user_session.get(\"runnable\"))  # type: Runnable\n",
    "\n",
    "    msg = cl.Message(content=\"\")\n",
    "\n",
    "    async for chunk in runnable.astream(\n",
    "        {\"question\": message.content},\n",
    "        config=RunnableConfig(callbacks=[cl.LangchainCallbackHandler()]),\n",
    "    ):\n",
    "        await msg.stream_token(chunk)\n",
    "\n",
    "    await msg.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485198cb-d383-4003-900e-d7940eb96729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
