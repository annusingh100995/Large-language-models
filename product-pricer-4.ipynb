{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc73a9b6-f87d-4d2c-839a-f3e24630d9ad",
   "metadata": {},
   "source": [
    "Product pricer using LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "481d9e2e-c3ce-4f23-b34b-eeb5232b8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from openai import OpenAI\n",
    "import google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918923b2-0786-4dbb-8e18-cc173b4bb4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enviroments\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "\n",
    "#Logging to HuggingFace\n",
    "hf_token = os.environ['HUGGINGFACEHUB_API_TOKEN']\n",
    "login(hf_token,add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "143ee1e6-6147-4cce-805f-4368ceef7ef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from items import Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de333607-ba7d-4431-b610-7d5bc9bb8c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from testing import Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79cf1689-f71f-4cf2-87ea-ca6b642ad30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66b6f58c-fa08-48df-a19d-411eeec0afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "761c4beb-ddaf-4464-b0f0-2db6195cc1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "with open('train.pkl','rb') as file:\n",
    "    train = pickle.load(file)\n",
    "with open('test.pkl','rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70e7b8a0-fcae-4658-97e2-e9ae1548047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_train = train[:50]\n",
    "fine_tune_validation = train[50:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842ffb16-7fdb-4bfb-ae22-5bc2d6e669dc",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdb4bdfc-9b86-43cc-be7b-9ebf6ae03351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating JSONL jsonline format\n",
    "\n",
    "def messages_for(item):\n",
    "    system_messgae = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
    "    user_prompt = item.test_prompt().replace(\"to the nearest dollar\",\"\").replace(\"\\n\\nPrice is $\",\"\")\n",
    "    return[\n",
    "        {\"role\":\"system\",\"content\":system_messgae},\n",
    "        {\"role\":\"system\",\"content\":user_prompt},\n",
    "        {\"role\":\"assistant\",\"content\":f\"Price is ${item.price:.2f}\"}\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b521cac-b6e8-4d99-946e-842ab66d1574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COnvert itens into a list of json object - jsonl\n",
    "# Each ros is of this form:\n",
    "# {\"messgae\":[{\"role\":\"system\",\"content\":\"You estimate...\"}]}\n",
    "\n",
    "def make_jsonl(items):\n",
    "    result = \"\"\n",
    "    for item in items:\n",
    "        messages = messages_for(item)\n",
    "        message_str = json.dumps(messages)\n",
    "        result += '{\"messgaes\": ' + message_str + '}\\n'\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20377790-f85c-421f-9828-56c48c18c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COnvert items to jsonl and write into afile\n",
    "def write_jsnol(items, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        jsnol = make_jsonl(items)\n",
    "        f.write(jsnol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58bdd585-51bb-4cde-a600-07898eea3c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsnol(fine_tune_train, \"fine_tune_train.jsonl\")\n",
    "write_jsnol(fine_tune_validation,\"fine_tune_validation.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50a4a1a0-a422-4c83-8eea-e783c3829db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fine_tune_train.jsonl\", 'rb')as f:\n",
    "    train_file = openai.files.create(file=f, purpose=\"fine-tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37fa9237-c38a-4d69-b79a-18f912dbbfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fine_tune_validation.jsonl\", \"rb\") as f:\n",
    "    validation_file = openai.files.create(file=f, purpose=\"fine-tune\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a2816f-be1f-4f9c-87d8-df1bc0a6c103",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71e3d98a-a345-403c-a75f-1ab0bf4e8af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_integration = {\"type\": \"wandb\", \"wandb\": {\"project\": \"gpt-pricer\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "faf4fa3a-1b36-42da-9adc-1934a19ac981",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'invalid_request_error', 'param': None, 'code': 'exceeded_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfine_tuning\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini-2024-07-18\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn_epochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpricer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\openai\\resources\\fine_tuning\\jobs\\jobs.py:159\u001b[39m, in \u001b[36mJobs.create\u001b[39m\u001b[34m(self, model, training_file, hyperparameters, integrations, metadata, method, seed, suffix, validation_file, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m     65\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     66\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     81\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m     82\u001b[39m ) -> FineTuningJob:\n\u001b[32m     83\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[33;03m    Creates a fine-tuning job which begins the process of creating a new model from\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[33;03m    a given dataset.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    157\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/fine_tuning/jobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining_file\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhyperparameters\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mintegrations\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mintegrations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmethod\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msuffix\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalidation_file\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43mjob_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mJobCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFineTuningJob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\openai\\_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\openai\\_base_client.py:919\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    917\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\openai\\_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1020\u001b[39m         err.response.read()\n\u001b[32m   1022\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1026\u001b[39m     cast_to=cast_to,\n\u001b[32m   1027\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1031\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1032\u001b[39m )\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'invalid_request_error', 'param': None, 'code': 'exceeded_quota'}}"
     ]
    }
   ],
   "source": [
    "openai.fine_tuning.jobs.create(\n",
    "    training_file=train_file.id,\n",
    "    validation_file=validation_file.id,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    seed=42,\n",
    "    hyperparameters={\"n_epochs\": 1},\n",
    "    suffix=\"pricer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "848d8f16-28c3-4810-b64c-5b0101eab0b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-04-17\n",
      "models/gemini-2.5-flash-preview-04-17-thinking\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n",
      "models/gemini-2.0-flash-live-001\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "client = genai.Client() # Get the key from the GOOGLE_API_KEY env variable\n",
    "\n",
    "for model_info in client.models.list():\n",
    "    print(model_info.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33d6fbfc-d7ce-4cd0-a542-78bca27f0018",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': '* CreateTunedModelRequest.tuned_model.base_model: Unexpected model name format.\\n* CreateTunedModelRequest.tuned_model.tuning_task.training_data: Too few training data.\\n', 'status': 'INVALID_ARGUMENT'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tuning_job = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtunings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodels/models/gemini-1.5-flash-001-tuning\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateTuningJobConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepoch_count\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtuned_model_display_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest tuned model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\google\\genai\\_common.py:312\u001b[39m, in \u001b[36mexperimental_warning.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    306\u001b[39m   warning_done = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    307\u001b[39m   warnings.warn(\n\u001b[32m    308\u001b[39m       message=message,\n\u001b[32m    309\u001b[39m       category=errors.ExperimentalWarning,\n\u001b[32m    310\u001b[39m       stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    311\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\google\\genai\\tunings.py:1008\u001b[39m, in \u001b[36mTunings.tune\u001b[39m\u001b[34m(self, base_model, training_dataset, config)\u001b[39m\n\u001b[32m   1002\u001b[39m   tuning_job = \u001b[38;5;28mself\u001b[39m._tune(\n\u001b[32m   1003\u001b[39m       base_model=base_model,\n\u001b[32m   1004\u001b[39m       training_dataset=training_dataset,\n\u001b[32m   1005\u001b[39m       config=config,\n\u001b[32m   1006\u001b[39m   )\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m   operation = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tune_mldev\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m      \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m operation.metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mtunedModel\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m operation.metadata:\n\u001b[32m   1014\u001b[39m     tuned_model_name = operation.metadata[\u001b[33m'\u001b[39m\u001b[33mtunedModel\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\google\\genai\\tunings.py:949\u001b[39m, in \u001b[36mTunings._tune_mldev\u001b[39m\u001b[34m(self, base_model, training_dataset, config)\u001b[39m\n\u001b[32m    946\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m    947\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m response_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_client.vertexai:\n\u001b[32m    954\u001b[39m   response_dict = _Operation_from_mldev(\u001b[38;5;28mself\u001b[39m._api_client, response_dict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\google\\genai\\_api_client.py:742\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    734\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    737\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    738\u001b[39m ):\n\u001b[32m    739\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m    740\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m    741\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m742\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    743\u001b[39m   json_response = response.json\n\u001b[32m    744\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m json_response:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\google\\genai\\_api_client.py:671\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    664\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m    665\u001b[39m       method=http_request.method,\n\u001b[32m    666\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    669\u001b[39m       timeout=http_request.timeout,\n\u001b[32m    670\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m671\u001b[39m   \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    672\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m    673\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m    674\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\google\\genai\\errors.py:101\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m     99\u001b[39m status_code = response.status_code\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    103\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[31mClientError\u001b[39m: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': '* CreateTunedModelRequest.tuned_model.base_model: Unexpected model name format.\\n* CreateTunedModelRequest.tuned_model.tuning_task.training_data: Too few training data.\\n', 'status': 'INVALID_ARGUMENT'}}"
     ]
    }
   ],
   "source": [
    "tuning_job = client.tunings.tune(\n",
    "    base_model='models/models/gemini-1.5-flash-001-tuning',\n",
    "    training_dataset=train_file,\n",
    "    config=types.CreateTuningJobConfig(\n",
    "        epoch_count= 2,\n",
    "        batch_size=4,\n",
    "        learning_rate=0.001,\n",
    "        tuned_model_display_name=\"test tuned model\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7eab9cc-2f4f-489e-9c56-4f62a901b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from google.genai import types\n",
    "from google.genai.types import TuningDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bc63668-cd1e-498f-8422-e13ef5ff3b80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_chat_jsonl_to_tuning_dataset(path):\n",
    "    examples = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            entry = json.loads(line)\n",
    "            messages = entry.get(\"messages\", [])\n",
    "\n",
    "            input_parts = []\n",
    "            output_text = None\n",
    "\n",
    "            for m in messages:\n",
    "                role = m.get(\"role\")\n",
    "                content = m.get(\"content\", \"\")\n",
    "\n",
    "                if role == \"assistant\":\n",
    "                    output_text = content  # Assume only one assistant reply\n",
    "                else:\n",
    "                    input_parts.append(f\"{role}: {content}\")\n",
    "\n",
    "            if input_parts and output_text:\n",
    "                text_input = \"\\n\".join(input_parts)\n",
    "                examples.append(TuningExample(text_input=text_input, output=output_text))\n",
    "\n",
    "    return TuningDataset(examples=examples)\n",
    "\n",
    "# Usage\n",
    "training_dataset = load_chat_jsonl_to_tuning_dataset(\"fine_tune_train.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ed82a89-4336-40c1-a541-f81fc3fb2567",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client() # Get the key from the GOOGLE_API_KEY env variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d150575f-7a1d-4557-99ca-f3ef078dc17b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': \"* CreateTunedModelRequest.tuned_model.tuning_task.training_data: Too few training data.\\n* CreateTunedModelRequest.tuned_model.tuning_task.training_data.examples.example_list: required one_of 'example_list' must have one initialized field\\n\", 'status': 'INVALID_ARGUMENT'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tuning_job = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtunings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodels/gemini-1.5-flash-001-tuning\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateTuningJobConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepoch_count\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtuned_model_display_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-fine-tuned-pricer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\google\\genai\\_common.py:312\u001b[39m, in \u001b[36mexperimental_warning.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    306\u001b[39m   warning_done = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    307\u001b[39m   warnings.warn(\n\u001b[32m    308\u001b[39m       message=message,\n\u001b[32m    309\u001b[39m       category=errors.ExperimentalWarning,\n\u001b[32m    310\u001b[39m       stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    311\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\google\\genai\\tunings.py:1008\u001b[39m, in \u001b[36mTunings.tune\u001b[39m\u001b[34m(self, base_model, training_dataset, config)\u001b[39m\n\u001b[32m   1002\u001b[39m   tuning_job = \u001b[38;5;28mself\u001b[39m._tune(\n\u001b[32m   1003\u001b[39m       base_model=base_model,\n\u001b[32m   1004\u001b[39m       training_dataset=training_dataset,\n\u001b[32m   1005\u001b[39m       config=config,\n\u001b[32m   1006\u001b[39m   )\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m   operation = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tune_mldev\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m      \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m operation.metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mtunedModel\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m operation.metadata:\n\u001b[32m   1014\u001b[39m     tuned_model_name = operation.metadata[\u001b[33m'\u001b[39m\u001b[33mtunedModel\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\google\\genai\\tunings.py:949\u001b[39m, in \u001b[36mTunings._tune_mldev\u001b[39m\u001b[34m(self, base_model, training_dataset, config)\u001b[39m\n\u001b[32m    946\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m    947\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m response_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_client.vertexai:\n\u001b[32m    954\u001b[39m   response_dict = _Operation_from_mldev(\u001b[38;5;28mself\u001b[39m._api_client, response_dict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\google\\genai\\_api_client.py:742\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    734\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    737\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    738\u001b[39m ):\n\u001b[32m    739\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m    740\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m    741\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m742\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    743\u001b[39m   json_response = response.json\n\u001b[32m    744\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m json_response:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\google\\genai\\_api_client.py:671\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    664\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m    665\u001b[39m       method=http_request.method,\n\u001b[32m    666\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    669\u001b[39m       timeout=http_request.timeout,\n\u001b[32m    670\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m671\u001b[39m   \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    672\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m    673\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m    674\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\llms\\Lib\\site-packages\\google\\genai\\errors.py:101\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m     99\u001b[39m status_code = response.status_code\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    103\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[31mClientError\u001b[39m: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': \"* CreateTunedModelRequest.tuned_model.tuning_task.training_data: Too few training data.\\n* CreateTunedModelRequest.tuned_model.tuning_task.training_data.examples.example_list: required one_of 'example_list' must have one initialized field\\n\", 'status': 'INVALID_ARGUMENT'}}"
     ]
    }
   ],
   "source": [
    "tuning_job = client.tunings.tune(\n",
    "    base_model='models/gemini-1.5-flash-001-tuning',\n",
    "    training_dataset=training_dataset,\n",
    "    config=types.CreateTuningJobConfig(\n",
    "        epoch_count= 5,\n",
    "        batch_size=4,\n",
    "        learning_rate=0.001,\n",
    "        tuned_model_display_name=\"gemini-fine-tuned-pricer\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2fc2c38c-9b51-4823-810c-5de03178b21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples:\", len(training_dataset.examples))\n",
    "for ex in training_dataset.examples[:3]:  # preview a few\n",
    "    print(\"INPUT:\", ex.text_input)\n",
    "    print(\"OUTPUT:\", ex.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9efb147-e05f-4a5c-a736-9f676410d469",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CreateTuningJobConfig' from 'google.genai.models' (C:\\Users\\Annu\\anaconda3\\envs\\llms\\Lib\\site-packages\\google\\genai\\models.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CreateTuningJobConfig\n\u001b[32m      3\u001b[39m tuning_job = client.tunings.tune(\n\u001b[32m      4\u001b[39m     base_model=\u001b[33m\"\u001b[39m\u001b[33mmodels/gemini-1.5-flash-001-tuning\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     training_dataset=training_dataset,\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     )\n\u001b[32m     12\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'CreateTuningJobConfig' from 'google.genai.models' (C:\\Users\\Annu\\anaconda3\\envs\\llms\\Lib\\site-packages\\google\\genai\\models.py)"
     ]
    }
   ],
   "source": [
    "from google.genai.models import CreateTuningJobConfig\n",
    "\n",
    "tuning_job = client.tunings.tune(\n",
    "    base_model=\"models/gemini-1.5-flash-001-tuning\",\n",
    "    training_dataset=training_dataset,\n",
    "    config=CreateTuningJobConfig(\n",
    "        epoch_count=5,\n",
    "        batch_size=4,\n",
    "        learning_rate=0.001,\n",
    "        tuned_model_display_name=\"price-estimation-model\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64382481-e1d4-494f-bf75-f5d56612da50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-04-17\n",
      "models/gemini-2.5-flash-preview-04-17-thinking\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n",
      "models/gemini-2.0-flash-live-001\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "client = genai.Client() # Get the key from the GOOGLE_API_KEY env variable\n",
    "\n",
    "for model_info in client.models.list():\n",
    "    print(model_info.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb752bad-019a-4c28-bc88-0af48ed23fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tuning model\n",
    "training_dataset =  [\n",
    "    [\"1\", \"2\"],\n",
    "    [\"3\", \"4\"],\n",
    "    [\"-3\", \"-2\"],\n",
    "    [\"twenty two\", \"twenty three\"],\n",
    "    [\"two hundred\", \"two hundred one\"],\n",
    "    [\"ninety nine\", \"one hundred\"],\n",
    "    [\"8\", \"9\"],\n",
    "    [\"-98\", \"-97\"],\n",
    "    [\"1,000\", \"1,001\"],\n",
    "    [\"10,100,000\", \"10,100,001\"],\n",
    "    [\"thirteen\", \"fourteen\"],\n",
    "    [\"eighty\", \"eighty one\"],\n",
    "    [\"one\", \"two\"],\n",
    "    [\"three\", \"four\"],\n",
    "    [\"seven\", \"eight\"],\n",
    "]\n",
    "training_dataset=types.TuningDataset(\n",
    "        examples=[\n",
    "            types.TuningExample(\n",
    "                text_input=i,\n",
    "                output=o,\n",
    "            )\n",
    "            for i,o in training_dataset\n",
    "        ],\n",
    "    )\n",
    "tuning_job = client.tunings.tune(\n",
    "    base_model='models/gemini-1.5-flash-001-tuning',\n",
    "    training_dataset=training_dataset,\n",
    "    config=types.CreateTuningJobConfig(\n",
    "        epoch_count= 5,\n",
    "        batch_size=4,\n",
    "        learning_rate=0.001,\n",
    "        tuned_model_display_name=\"test tuned model\"\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb679db7-e228-4c38-b7cb-07edc75a57d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m response = client.models.generate_content(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     model=\u001b[43mtuning_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtuned_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m,\n\u001b[32m      3\u001b[39m     contents=\u001b[33m'\u001b[39m\u001b[33mIII\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=tuning_job.tuned_model.model,\n",
    "    contents='III'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb347a3e-26a7-455e-89a6-dbb944a15722",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_job_name = tuning_job.name  # Save this after submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dac980ef-fa99-4074-88e2-60c9c5333620",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tunings' object has no attribute 'get_tuning_job'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m completed_job = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtunings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tuning_job\u001b[49m(name=tuning_job_name)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Now get the tuned model\u001b[39;00m\n\u001b[32m      4\u001b[39m tuned_model_name = completed_job.tuned_model.model\n",
      "\u001b[31mAttributeError\u001b[39m: 'Tunings' object has no attribute 'get_tuning_job'"
     ]
    }
   ],
   "source": [
    "completed_job = client.tunings.get_tuning_job(name=tuning_job_name)\n",
    "\n",
    "# Now get the tuned model\n",
    "tuned_model_name = completed_job.tuned_model.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb00453f-a144-4462-9ee1-6569b6ed342e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
