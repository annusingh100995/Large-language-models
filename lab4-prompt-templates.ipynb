{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4974b19f-b094-4adf-84f5-30033dc668b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08c33a7e-c117-4a58-82cd-0e34fec89006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Laoding the environment variable\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efbe95f2-fec4-4db8-a05b-d150720fa0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7f298ae-13f3-44c1-a9d8-2bd6b9e077a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Prompt from Template --\n",
      "messages=[HumanMessage(content='Tell me a joke about cats.', additional_kwargs={}, response_metadata={})] \n",
      "\n",
      "Why did the cat join the Red Cross?\n",
      "\n",
      "Because he wanted to be a first aid kit!\n"
     ]
    }
   ],
   "source": [
    "# Create a chattemplate using a string\n",
    "\n",
    "template1 = \"Tell me a joke about {topic}.\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template1)\n",
    "print(\"-- Prompt from Template --\")\n",
    "prompt = prompt_template.invoke({\"topic\":\"cats\"})\n",
    "print(f\"{prompt} \\n\")\n",
    "\n",
    "result = model.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "410df576-2895-49b5-90de-81b45a66e04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --- Prompt with multiple Placeholder --- \n",
      " \n",
      "messages=[HumanMessage(content=' You are a helpful assitant.\\nHuman : Tell me a funny story about a bunny.\\nAssistant :', additional_kwargs={}, response_metadata={})] \n",
      "\n",
      "Barnaby the bunny was convinced he was a master magician. He’d seen a show on TV once, and immediately decided he had the natural talent. The problem? He wasn't very good.\n",
      "\n",
      "His first trick was supposed to be the classic \"pull a carrot out of a hat.\" He borrowed Mrs. Higgins' best gardening hat (much to her chagrin, evidenced by the lettuce she later found \"mysteriously\" scattered around his burrow). He placed the hat on the ground, mumbled some gibberish that sounded vaguely like \"Abraca-carrot-dabra,\" and then...nothing. He patted the hat, hopped around it, and even tried to peek inside without toppling it over.\n",
      "\n",
      "Finally, in a fit of frustration, he lifted the hat. Instead of a plump, juicy carrot, he revealed...a very confused earthworm.\n",
      "\n",
      "Barnaby, flustered, stammered, \"Ahem, a *slightly* different carrot than expected! This, uh, is a *worm-carrot*! Very rare! Very…wiggly!\"\n",
      "\n",
      "The earthworm, probably equally confused, just wriggled deeper into the hat.\n",
      "\n",
      "Undeterred, Barnaby tried again. This time, he was going to make a rock disappear. He placed a small pebble under a handkerchief, said his magic words (this time incorporating the word \"pebble-doodle-doo\"), and whipped the handkerchief away with a flourish.\n",
      "\n",
      "The rock was still there.\n",
      "\n",
      "He tried again. Same result.\n",
      "\n",
      "He tried a *third* time, this time adding a dramatic jump and a loud squeak to his spell. The rock remained stubbornly in place.\n",
      "\n",
      "Finally, Barnaby, in a fit of pique, snatched the rock up and chucked it as far as he could.\n",
      "\n",
      "He turned to the imaginary audience, puffed out his chest, and declared, \"And *that*, my friends, is how you make a rock disappear...permanently!\"\n",
      "\n",
      "He hopped away, leaving behind a bewildered earthworm in a hat and a small divot in the ground where the rock used to be, convinced he was the greatest magician the bunny world had ever seen. He just needed to work on his, uh, *delivery*. And maybe his actual magic.\n"
     ]
    }
   ],
   "source": [
    "# Create prompt with multiple placeholders\n",
    "template_multiple = \"\"\" You are a helpful assitant.\n",
    "Human : Tell me a {adjective} story about a {animal}.\n",
    "Assistant :\"\"\"\n",
    "prompt_multiple = ChatPromptTemplate.from_template(template_multiple)\n",
    "prompt = prompt_multiple.invoke({\"adjective\":\"funny\", \"animal\":\"bunny\"})\n",
    "print(\"\\n --- Prompt with multiple Placeholder --- \\n \")\n",
    "print(f\"{prompt} \\n\")\n",
    "\n",
    "result = model.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0c9882b-a1a9-494a-8725-3bf8314ec61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---Prompt with System and Human Messages (tuple)---\n",
      "\n",
      "messages=[SystemMessage(content='You are a comedian who tells jokes about doctors', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me a 3 jokes.', additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "Alright, alright, settle down folks! You know, I was thinking about doctors the other day... those guys are something else. Here are a few zingers for ya:\n",
      "\n",
      "1.  Why did the doctor bring a red pen to the hospital? Because he wanted to draw blood! I'm here all week, folks, try the veal!\n",
      "\n",
      "2.  My doctor told me I need to cut back on drinking. So I said, \"Okay, doc, I'll just drink in a wider glass!\" What can I say? I'm a problem solver.\n",
      "\n",
      "3.  A guy goes to the doctor and says, \"Doc, I think I'm a moth!\" The doctor says, \"Well, you need to get some help. Tell me, why do you think you're a moth?\" The guy says, \"Because I keep trying to get into the light!\" The doctor replies, \"Then go home, the lightbulb is out!\"\n",
      "\n",
      "... I'll be here all night, don't forget to tip your waitresses!\n"
     ]
    }
   ],
   "source": [
    "# Prompt with system and human messages\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a comedian who tells jokes about {topic}\"),\n",
    "    (\"human\", \"Tell me a {joke_count} jokes.\"),\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "prompt = prompt_template.invoke({\"topic\":\"doctors\", \"joke_count\":3})\n",
    "print(\"\\n---Prompt with System and Human Messages (tuple)---\\n\")\n",
    "print(f\"{prompt}\\n\")\n",
    "\n",
    "result = model.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46db843-aed9-4afe-919c-4473e826ba77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
